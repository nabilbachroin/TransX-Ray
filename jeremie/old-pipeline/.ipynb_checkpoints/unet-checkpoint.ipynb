{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e2109f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_fold= 1\n",
    "total_fold= '5'\n",
    "use_enchanced_dataset= False\n",
    "model_name= \"U-NET\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477ca1e-19f8-49f1-aaac-01cf171a7949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from keras import *\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential, model_from_json, load_model\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "#from keras.applications.densenet import DenseNet121\n",
    "\n",
    "import util\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.initializers import RandomNormal\n",
    "# from swintransformer import SwinTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cefbfbf-fcc7-4bae-8e75-80ca8bccd41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936dfef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "print(\"Test built: {}\".format(tf.test.is_built_with_cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53372361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_enchanced_dataset == True:\n",
    "    IMAGE_DIR = \"/home/cries/Dataset/X-Ray/enchanced/\"\n",
    "else:\n",
    "    IMAGE_DIR = \"/home/cries/Dataset/X-Ray/original/images/\"\n",
    "    \n",
    "train_df= pd.read_csv(\"/home/cries/Dataset/X-Ray/DataFrame/\" + str(total_fold) + \"Fold/\" + \"train_Fold\" + str(n_fold) + \".csv\").loc[:,'Image Index':]\n",
    "test_df= pd.read_csv(\"/home/cries/Dataset/X-Ray/DataFrame/\" + str(total_fold) + \"Fold/\" + \"test_Fold\" + str(n_fold) + \".csv\").loc[:,'Image Index':]\n",
    "\n",
    "labels = ['No Findings',\n",
    "          'Cardiomegaly', \n",
    "          'Emphysema', \n",
    "          'Effusion', \n",
    "          'Hernia', \n",
    "          'Infiltration', \n",
    "          'Mass', \n",
    "          'Nodule', \n",
    "          'Atelectasis',\n",
    "          'Pneumothorax',\n",
    "          'Pleural_Thickening', \n",
    "          'Pneumonia', \n",
    "          'Fibrosis', \n",
    "          'Edema', \n",
    "          'Consolidation']\n",
    "\n",
    "print(\"Leakage between train and test: {}\".format(util.check_for_leakage(train_df, test_df, 'Image Index')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b0e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting\n",
    "seed= 1\n",
    "batch_size= 8\n",
    "# target_w= 320; target_h= 320; dim= (3,)\n",
    "target_w= 224; target_h= 224; dim= (3,)\n",
    "image_size_target= (target_w,target_h)\n",
    "image_shape= image_size_target + dim\n",
    "class_mode= 'raw'   # raw, categorical \n",
    "\n",
    "use_aug= False\n",
    "use_normalize= True\n",
    "index_col= \"Image Index\"\n",
    "labels_col= labels\n",
    "\n",
    "def prepare_generator(use_Aug, use_Normalize):\n",
    "    # == Aug Image\n",
    "    if use_Aug== True and use_Normalize== False:\n",
    "        return ImageDataGenerator(\n",
    "            rescale= 1./255,        \n",
    "            horizontal_flip= True,\n",
    "            height_shift_range= 0.5,\n",
    "            width_shift_range= 0.5,\n",
    "            vertical_flip= True,\n",
    "            rotation_range= 20,\n",
    "            fill_mode= \"nearest\"\n",
    "            )\n",
    "    # == Normalize Image\n",
    "    if use_Aug== False and use_Normalize== True:\n",
    "        return ImageDataGenerator(\n",
    "            samplewise_center= True,\n",
    "            samplewise_std_normalization= True\n",
    "            )\n",
    "    # == Without\n",
    "    if use_Aug== False and use_Normalize== False:\n",
    "        return ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b674ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Image Train Generator\n",
    "print(\"============ getting train generator ===========\") \n",
    "image_train= prepare_generator(False, True).flow_from_dataframe(\n",
    "    dataframe= train_df,\n",
    "    directory= IMAGE_DIR,\n",
    "    x_col= index_col,\n",
    "    y_col= labels,\n",
    "    class_mode= class_mode,\n",
    "    batch_size= batch_size,\n",
    "    shuffle= True,\n",
    "    target_size= image_size_target\n",
    ")\n",
    "\n",
    "# === Image Validation and Test Generator\n",
    "print(\"\")\n",
    "print(\"==== getting train and test/valid generators ====\")\n",
    "raw_train_generator= prepare_generator(False, False).flow_from_dataframe(\n",
    "                        dataframe= train_df,\n",
    "                        directory= IMAGE_DIR,\n",
    "                        x_col= index_col,\n",
    "                        y_col= labels,\n",
    "                        class_mode= class_mode,\n",
    "                        batch_size= batch_size,\n",
    "                        shuffle= True,\n",
    "                        target_size= image_size_target\n",
    "                    )\n",
    "batch= raw_train_generator.next()\n",
    "data_sample= batch[0]\n",
    "imagegenerator= prepare_generator(False, True)\n",
    "imagegenerator.fit(data_sample)\n",
    "image_val = imagegenerator.flow_from_dataframe(\n",
    "                        dataframe= test_df,\n",
    "                        directory= IMAGE_DIR,\n",
    "                        x_col= index_col,\n",
    "                        y_col= labels,\n",
    "                        class_mode= class_mode,\n",
    "                        batch_size= batch_size,\n",
    "                        shuffle= False,\n",
    "                        target_size= image_size_target\n",
    "                    )\n",
    "\n",
    "x, y = image_train.__getitem__(0)\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(x[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8b1ce-513f-49d8-9cbb-a749871fad1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8da0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=labels, height=np.mean(image_train.labels, axis=0))\n",
    "plt.title(\"Frequency of Each Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c6c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_class_freqs(labels):\n",
    "    # total number of patients (rows)\n",
    "    N = labels.shape[0]\n",
    "    positive_frequencies = np.sum(labels, axis = 0) / N\n",
    "    negative_frequencies = 1 - positive_frequencies\n",
    "    return positive_frequencies, negative_frequencies\n",
    "\n",
    "freq_pos, freq_neg = compute_class_freqs(image_train.labels)\n",
    "freq_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad2b61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.xticks(rotation=90)\n",
    "f = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7428e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_weights = freq_neg\n",
    "neg_weights = freq_pos\n",
    "pos_contribution = freq_pos * pos_weights \n",
    "neg_contribution = freq_neg * neg_weights\n",
    "\n",
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": pos_contribution})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} \n",
    "                        for l,v in enumerate(neg_contribution)], ignore_index=True)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674bb3e-aa68-42f9-bd52-807f16325506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_class = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d3f68-2c52-41b4-be2b-0a9cce52b32d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs= Input(shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03c3d7-f7e3-4815-b976-9c887898e659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(input_layer, start_neurons):\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    # pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    # pool2 = Dropout(0.5)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    # pool3 = Dropout(0.5)(pool3)\n",
    "\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    # pool4 = Dropout(0.5)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n",
    "    \n",
    "#     deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "#     uconv4 = concatenate([deconv4, conv4])\n",
    "#     uconv4 = Dropout(0.5)(uconv4)\n",
    "#     uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "#     uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "\n",
    "#     deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "#     uconv3 = concatenate([deconv3, conv3])\n",
    "#     uconv3 = Dropout(0.5)(uconv3)\n",
    "#     uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "#     uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "\n",
    "#     deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "#     uconv2 = concatenate([deconv2, conv2])\n",
    "#     uconv2 = Dropout(0.5)(uconv2)\n",
    "#     uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "#     uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "\n",
    "#     deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "#     uconv1 = concatenate([deconv1, conv1])\n",
    "#     uconv1 = Dropout(0.5)(uconv1)\n",
    "#     uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "#     uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    \n",
    "#     output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"relu\")(uconv1)\n",
    "    output_layer = GlobalMaxPooling2D()(convm)\n",
    "    output_layer = LayerNormalization()(output_layer)\n",
    "    \n",
    "    output_layer = Dense(64, activation=\"LeakyReLU\")(output_layer)\n",
    "    output_layer = Dense(num_class, activation=\"sigmoid\")(output_layer)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "input_layer = inputs\n",
    "output = build_model(input_layer, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec164f73-08b6-47ba-be27-4bb6dc6b1eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(input_layer, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c5b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5447d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3380401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merged_neck = keras.layers.concatenate([Swin_Model.output, mb3_Model.output])\n",
    "# neck = BatchNormalization()(merged_neck)\n",
    "\n",
    "# dense = Dense(16, activation='LeakyReLU')(neck)\n",
    "# dense = Dense(4)(dense)\n",
    "# dense = Dense(16, activation='LeakyReLU')(dense)\n",
    "\n",
    "# merged_head = keras.layers.concatenate([neck, dense])\n",
    "\n",
    "# head = Dense(32, activation='LeakyReLU')(merged_head)\n",
    "# head = Dense(8)(head)\n",
    "# head = Dense(32, activation='LeakyReLU')(head)\n",
    "\n",
    "# head = Dense(num_class, activation='softmax')(head)\n",
    "\n",
    "# model = Model(inputs=inputs, outputs=head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaae8e2-d0d0-426e-9083-dc61b99c5b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb048dce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch = 25\n",
    "\n",
    "lr = 4e-5\n",
    "decay_rate = lr / epoch\n",
    "momentum = 0.99\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=decay_rate, beta_2=decay_rate*decay_rate, epsilon=1e-07, amsgrad=False)\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=lr, momentum=momentum, weight_decay=decay_rate, nesterov=False)\n",
    "checkpoint = ModelCheckpoint(\"ckp_{}.hdf5\".format(model_name), monitor='loss', verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "# class_weigths = dict(zip(range(len(neg_weights)), neg_weights))\n",
    "# weighted_loss = get_weighted_loss(pos_weights, neg_weights)\n",
    "bfce_ls = tf.losses.BinaryCrossentropy(label_smoothing = 0.0)\n",
    "\n",
    "metric_auc = tf.keras.metrics.AUC(multi_label=True)\n",
    "\n",
    "model.compile(loss=bfce_ls, optimizer=sgd, metrics=[metric_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f9abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history = model.fit(image_train, epochs=epoch, validation_data=image_val, callbacks=[checkpoint,PlotLossesKeras()],verbose=1)\n",
    "end_train = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46c5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('model_{}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed547c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model.save_weights(\"{}_weights.h5\".format(model_name))\n",
    "file_stats = os.stat(\"{}_weights.h5\".format(model_name))\n",
    "model_size = round(file_stats.st_size / (1024 * 1024), 2)\n",
    "model_parameter = model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ce26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca88f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load Model\n",
    "from tensorflow import keras\n",
    "model_fusion = keras.models.load_model('./model_{}/'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448bb8d8-567f-4250-8a1c-4e3ff989d7be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_vals = model_fusion.predict_generator(image_val, steps = len(image_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86268429-51e9-48e4-87fd-0a164283a3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auc_rocs = util.get_roc_curve(labels, predicted_vals, image_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde830f6-9ced-4b64-a23d-1d5e288db144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47477536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import multilabel_confusion_matrix\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# start = time.time()\n",
    "# y_prob = model_fusion.predict(image_val)\n",
    "# end_test = time.time() - start\n",
    "\n",
    "# y_pred = np.argmax(y_prob, axis=1)\n",
    "# y_true = image_val.classes\n",
    "\n",
    "# print(\"Precision:\", precision_score(y_true, y_pred, average='weighted'), \"Recall:\", recall_score(y_true, y_pred, average='weighted'))\n",
    "\n",
    "# cm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# a = []\n",
    "\n",
    "# for i in range(len(cm)):\n",
    "#     a.append(cm[i].ravel())\n",
    "\n",
    "# tp, fn, fp, tn =np.sum(np.array(a), axis = 0)\n",
    "\n",
    "# print(\"tp, fn, fp, tn:\", tp, fn, fp, tn)\n",
    "\n",
    "# print(\"Specificity:\", tn / (tn+fp), \"Sensitivity:\", tp / (tp+fn))\n",
    "# print(\"F1-Score:\", f1_score(y_true, y_pred, average='weighted'), \"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "\n",
    "# Specificty = tn / (tn+fp)\n",
    "# Sensitivity = tp / (tp+fn)\n",
    "# F1_Score = f1_score(y_true, y_pred, average='weighted')\n",
    "# Accuracy = accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = [y_true, y_pred]\n",
    "# pd.DataFrame(result).to_csv(\"{}_{}_result.csv\".format(model_name, n_fold))\n",
    "# pd.DataFrame(y_prob).to_csv(\"{}_{}_probability.csv\".format(model_name, n_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eece65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_true, y_pred)\n",
    "# m_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "# print(fpr_keras, tpr_keras, thresholds_keras, m_auc)\n",
    "\n",
    "# from sklearn.metrics import auc\n",
    "# auc_keras = auc(fpr_keras, tpr_keras)\n",
    "# print(auc_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keep probabilities for the positive outcome only\n",
    "# lr_probs = y_prob[:, 1]\n",
    "# lr_auc = roc_auc_score(y_true, lr_probs)\n",
    "# print('Model Fusion: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# lr_fpr, lr_tpr, _ = roc_curve(y_true, lr_probs)\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# font={'size':'15'}\n",
    "# plt.rc('font',**font)\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "# plt.plot(lr_fpr, lr_tpr, marker='.', label='{} Model ROC curve (area = %0.2f)'.format(model_name) % lr_auc)\n",
    "\n",
    "# roc_auc = [lr_fpr, lr_fpr]\n",
    "# pd.DataFrame(roc_auc).to_csv(\"{}_roc_auc.csv\".format(model_name))\n",
    "\n",
    "# # axis labels\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# # show the legend\n",
    "# plt.legend()\n",
    "\n",
    "# AUC_Score = lr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a6ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result = [Specificty, Sensitivity, F1_Score, Accuracy, AUC_Score, end_train, end_test, model_size, model_parameter]\n",
    "# colname = ['Specificty', 'Sensitivity', 'F1_Score', 'Accuracy', 'AUC_Score', 'end_train', 'end_test', 'model_size', 'model_parameter']\n",
    "\n",
    "# pd.DataFrame([Result], columns=colname).to_csv(\"{}_fold_\".format(model_name)+str(n_fold)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(15, 15))\n",
    "\n",
    "# labels = [\"Sperm\", \"Impurity\"]\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "# plt.rcParams['figure.figsize']=[15,15]\n",
    "# font={'size':'30'}\n",
    "# plt.rc('font',**font)\n",
    "# disp.plot(cmap=plt.cm.Blues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jeremie_env",
   "language": "python",
   "name": "jeremie_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
