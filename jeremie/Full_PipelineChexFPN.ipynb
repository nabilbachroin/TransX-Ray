{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2109f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_fold= 1\n",
    "total_fold= '5'\n",
    "use_enchanced_dataset= False\n",
    "model_name= \"Full-ChexFPN\"\n",
    "\n",
    "full_dataset = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74026c35-a568-48bc-b31c-c97f6e659a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477ca1e-19f8-49f1-aaac-01cf171a7949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "# Keras\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, Sequential, model_from_json, load_model\n",
    "# from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras_retinanet import layers as rlayers\n",
    "\n",
    "\n",
    "import util\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936dfef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "print(\"Test built: {}\".format(tf.test.is_built_with_cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53372361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_enchanced_dataset == True:\n",
    "    IMAGE_DIR = \"/home/cries/Dataset/X-Ray/enchanced/\"\n",
    "else:\n",
    "    IMAGE_DIR = \"/home/cries/Dataset/X-Ray/full/images/\"\n",
    "    \n",
    "if full_dataset == True:\n",
    "    train_df= pd.read_csv(\"/home/cries/Dataset/X-Ray/DataFrame/official_train.csv\")\n",
    "    test_df= pd.read_csv(\"/home/cries/Dataset/X-Ray/DataFrame/official_test.csv\")\n",
    "else:    \n",
    "    train_df= pd.read_csv(\"/home/cries/Dataset/X-Ray/DataFrame/\" + str(total_fold) + \"Fold/\" + \"train_Fold\" + str(n_fold) + \".csv\").loc[:,'Image Index':]\n",
    "    test_df= pd.read_csv(\"/home/cries/Dataset/X-Ray/DataFrame/\" + str(total_fold) + \"Fold/\" + \"test_Fold\" + str(n_fold) + \".csv\").loc[:,'Image Index':]\n",
    "\n",
    "labels = ['No Finding',\n",
    "          'Cardiomegaly', \n",
    "          'Emphysema', \n",
    "          'Effusion', \n",
    "          'Hernia', \n",
    "          'Infiltration', \n",
    "          'Mass', \n",
    "          'Nodule', \n",
    "          'Atelectasis',\n",
    "          'Pneumothorax',\n",
    "          'Pleural_Thickening', \n",
    "          'Pneumonia', \n",
    "          'Fibrosis', \n",
    "          'Edema', \n",
    "          'Consolidation']\n",
    "\n",
    "print(\"Leakage between train and test: {}\".format(util.check_for_leakage(train_df, test_df, 'Image Index')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b0e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting\n",
    "seed= 1\n",
    "batch_size= 32\n",
    "# target_w= 320; target_h= 320; dim= (3,)\n",
    "target_w= 224; target_h= 224; dim= (3,)\n",
    "image_size_target= (target_w,target_h)\n",
    "image_shape= image_size_target + dim\n",
    "class_mode= 'raw'   # raw, categorical \n",
    "\n",
    "use_aug= False\n",
    "use_normalize= True\n",
    "index_col= \"Image Index\"\n",
    "labels_col= labels\n",
    "\n",
    "def prepare_generator(use_Aug, use_Normalize):\n",
    "    # == Aug Image\n",
    "    if use_Aug== True and use_Normalize== False:\n",
    "        return ImageDataGenerator(\n",
    "            rescale= 1./255,        \n",
    "            horizontal_flip= True,\n",
    "            # vertical_flip= False,\n",
    "            # shear_range=0.1,\n",
    "            # zoom_range=0.1,\n",
    "            # cval=0.0,\n",
    "            # fill_mode='constant',\n",
    "            # rotation_range = 10\n",
    "            )\n",
    "    # == Normalize Image\n",
    "    if use_Aug== False and use_Normalize== True:\n",
    "        return ImageDataGenerator(\n",
    "            rescale= 1./255,\n",
    "            # horizontal_flip=True,\n",
    "            samplewise_center= True,\n",
    "            samplewise_std_normalization= True\n",
    "            )\n",
    "    \n",
    "    # == Without\n",
    "    if use_Aug== False and use_Normalize== False:\n",
    "        return ImageDataGenerator(rescale= 1./255)\n",
    "    \n",
    "    if use_Aug== True and use_Normalize== True:\n",
    "        return ImageDataGenerator(\n",
    "            samplewise_center= True,\n",
    "            samplewise_std_normalization= True,\n",
    "            rescale= 1./255,        \n",
    "            horizontal_flip=True,\n",
    "            vertical_flip= False,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            cval=0.0,\n",
    "            fill_mode='constant',\n",
    "            rotation_range = 20\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b674ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Image Train Generator\n",
    "print(\"============ getting train generator ===========\") \n",
    "image_train= prepare_generator(use_Aug=True, use_Normalize=True).flow_from_dataframe(\n",
    "    dataframe= train_df,\n",
    "    directory= IMAGE_DIR,\n",
    "    x_col= index_col,\n",
    "    y_col= labels,\n",
    "    class_mode= class_mode,\n",
    "    batch_size= batch_size,\n",
    "    shuffle= True,\n",
    "    target_size= image_size_target\n",
    ")\n",
    "\n",
    "# === Image Validation and Test Generator\n",
    "print(\"\")\n",
    "print(\"==== getting train and test/valid generators ====\")\n",
    "raw_train_generator= prepare_generator(False, False).flow_from_dataframe(\n",
    "                        dataframe= train_df,\n",
    "                        directory= IMAGE_DIR,\n",
    "                        x_col= index_col,\n",
    "                        y_col= labels,\n",
    "                        class_mode= class_mode,\n",
    "                        batch_size= batch_size,\n",
    "                        shuffle= True,\n",
    "                        target_size= image_size_target\n",
    "                    )\n",
    "batch= raw_train_generator.next()\n",
    "data_sample= batch[0]\n",
    "imagegenerator= prepare_generator(False, True)\n",
    "imagegenerator.fit(data_sample)\n",
    "image_val = imagegenerator.flow_from_dataframe(\n",
    "                        dataframe= test_df,\n",
    "                        directory= IMAGE_DIR,\n",
    "                        x_col= index_col,\n",
    "                        y_col= labels,\n",
    "                        class_mode= class_mode,\n",
    "                        batch_size= batch_size,\n",
    "                        shuffle= False,\n",
    "                        target_size= image_size_target\n",
    "                    )\n",
    "\n",
    "x, y = image_train.__getitem__(0)\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(x[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8da0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=labels, height=np.mean(image_train.labels, axis=0))\n",
    "plt.title(\"Frequency of Each Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c6c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_class_freqs(labels):\n",
    "    # total number of patients (rows)\n",
    "    N = labels.shape[0]\n",
    "    positive_frequencies = np.sum(labels, axis = 0) / N\n",
    "    negative_frequencies = 1 - positive_frequencies\n",
    "    return positive_frequencies, negative_frequencies\n",
    "\n",
    "freq_pos, freq_neg = compute_class_freqs(image_train.labels)\n",
    "freq_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad2b61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.xticks(rotation=90)\n",
    "f = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7428e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_weights = freq_neg\n",
    "neg_weights = freq_pos\n",
    "pos_contribution = freq_pos * pos_weights \n",
    "neg_contribution = freq_neg * neg_weights\n",
    "\n",
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": pos_contribution})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} \n",
    "                        for l,v in enumerate(neg_contribution)], ignore_index=True)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2295fd-b282-4df0-8a61-0cf142e041a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578eae19-70df-480a-915e-a178ce3b16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = util.generate_class_weights(image_train.labels, multi_class=False, one_hot_encoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a75cbd-3e6b-4935-91fa-d77c33c82a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d3f68-2c52-41b4-be2b-0a9cce52b32d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5447d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674bb3e-aa68-42f9-bd52-807f16325506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_class = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d5a483-5f5b-48b8-a1b4-07ef532d11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_head(x, depth=[128, 128], dropout_rate=0.3):\n",
    "    for units in depth:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = layers.Dense(units, activation='selu')(x)\n",
    "        # x = BatchNormalization()(x)\n",
    "        # x = Dropout(dropout_rate)(x)\n",
    "        # x = Flatten()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b520f6b-e9ee-4eea-951b-bb57dd220f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09ee52-dcee-49f3-bac9-7dea0fdaedf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mdl1 = hub.KerasLayer(\"https://tfhub.dev/sayakpaul/swin_s3_tiny_224_fe/1\", trainable=False)(inputs)\n",
    "# swin_output = Flatten()(swin_output)\n",
    "\n",
    "# mdl1 = Model(inputs, mdl1)\n",
    "# mdl1.trainable = False\n",
    "\n",
    "# mdl2 = tf.keras.applications.DenseNet121(weights='imagenet', include_top=False)(inputs)\n",
    "\n",
    "# outputs = GlobalMaxPooling2D()(mdl2)\n",
    "# mdl2 = Model(inputs=inputs, outputs=outputs)\n",
    "# mdl2.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ab6ec-c143-459c-a8ce-1e618571cfe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_path = '/home/cries/Workshop/X-Ray/TransX-Ray/jeremie/chexnet_pretrained/brucechou1983_CheXNet_Keras_0.3.0_weights.h5'\n",
    "mdl = tf.keras.applications.DenseNet121(weights=weights_path, include_top=True, classes=14, input_tensor=inputs)\n",
    "\n",
    "base_model = Model(inputs=inputs, outputs=mdl.layers[-3].output)\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e34136-680a-4b3f-85a5-304c392f5a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286eb8ec-44aa-485b-8f82-fc03d442e1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_names = [\"pool2_conv\", \"pool3_conv\", \"pool4_conv\", \"relu\"]\n",
    "\n",
    "layer_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "x1, x2, x3, x4=layer_outputs\n",
    "\n",
    "x = BatchNormalization()(x4)\n",
    "x = GlobalMaxPooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b677e7-aee3-4b54-b205-895b2c2441d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_size = 256\n",
    "\n",
    "P6 = Conv2D(feature_size, kernel_size=3, strides=2, padding='same')(x4)\n",
    "\n",
    "P7 = Conv2D(feature_size, kernel_size=3, strides=2, padding='same', activation='relu')(P6)\n",
    "\n",
    "P5 = Conv2D(feature_size, kernel_size=1, strides=1, padding='same')(x4) # up\n",
    "P5_UP = rlayers.UpsampleLike()([P5, x3])\n",
    "P5 = Conv2D(feature_size, kernel_size=3, strides=1, padding='same')(P5)\n",
    "\n",
    "P4 = Conv2D(feature_size, kernel_size=1, strides=1, padding='same')(x3) # up\n",
    "P4 = Concatenate(axis=3)([P5_UP, P4])\n",
    "P4_UP = rlayers.UpsampleLike()([P4, x2])\n",
    "P4 = Conv2D(feature_size, kernel_size=3, strides=1, padding='valid')(P4)\n",
    "\n",
    "P3 = Conv2D(feature_size, kernel_size=1, strides=1, padding='same')(x2) # up\n",
    "P3 = Concatenate(axis=3)([P4_UP, P3])\n",
    "P3_UP = rlayers.UpsampleLike()([P3, x1])\n",
    "P3 = Conv2D(feature_size, kernel_size=3, strides=1, padding='valid')(P4)\n",
    "\n",
    "P2 = Conv2D(feature_size, kernel_size=1, strides=1, padding='same')(x1) # up\n",
    "P2 = Concatenate(axis=3)([P3_UP, P2])\n",
    "P2 = Conv2D(feature_size, kernel_size=3, strides=1, padding='valid')(P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6d0a5-9bd8-40d0-bdeb-64d679fb97e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_units = [2048]\n",
    "\n",
    "f0 = mlp_head(x, depth=hidden_units, dropout_rate=0.5)\n",
    "\n",
    "f1 = BatchNormalization()(P2)\n",
    "f1 = GlobalMaxPooling2D()(f1)\n",
    "f1 = mlp_head(f1, depth=hidden_units, dropout_rate=0.5)\n",
    "\n",
    "f2 = BatchNormalization()(P3)\n",
    "f2 = GlobalMaxPooling2D()(f2)\n",
    "f2 = mlp_head(f2, depth=hidden_units, dropout_rate=0.5)\n",
    "\n",
    "f3 = BatchNormalization()(P4)\n",
    "f3 = GlobalMaxPooling2D()(f3)\n",
    "f3 = mlp_head(f3, depth=hidden_units, dropout_rate=0.5)\n",
    "\n",
    "f4 = BatchNormalization()(P5)\n",
    "f4 = GlobalMaxPooling2D()(f4)\n",
    "f4 = mlp_head(f4, depth=hidden_units, dropout_rate=0.5)\n",
    "\n",
    "f5 = BatchNormalization()(P6)\n",
    "f5 = GlobalMaxPooling2D()(f5)\n",
    "f5 = mlp_head(f5, depth=hidden_units, dropout_rate=0.5)\n",
    "\n",
    "f6 = BatchNormalization()(P7)\n",
    "f6 = GlobalMaxPooling2D()(f6)\n",
    "f6 = mlp_head(f6, depth=hidden_units, dropout_rate=0.5)\n",
    "\n",
    "head = Concatenate()([f0, f1, f2, f3, f4, f5, f6])\n",
    "# head = Concatenate()([f1, f2, f3, f4, f5, f6])\n",
    "head = BatchNormalization()(head)\n",
    "\n",
    "head = mlp_head(head, depth= [2048, 1024], dropout_rate=0.0)\n",
    "\n",
    "predictions = Dense(num_class, activation='sigmoid')(head)\n",
    "model = Model(inputs=inputs, outputs=predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae307074-8cd2-4c72-ad3d-d78b49f5978f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08945c-5ecb-481f-a121-3437317fdfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './output_weights/{}'.format(model_name)\n",
    "weight_path = '{}_ckp_weights.h5'.format(model_name)\n",
    "\n",
    "output_weights_path = os.path.join(output_dir, weight_path)\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "adaptive_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode=\"min\", min_lr=5e-6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f63f16-b9f3-4acb-8fa4-81017a22c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = util.set_binary_crossentropy_weighted_loss(\n",
    "    positive_weights=pos_weights,\n",
    "    negative_weights=neg_weights)\n",
    "\n",
    "# train_steps = len(image_train) / 10\n",
    "# val_steps = len(image_val) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da26a7-4828-42dd-9583-a83b78f6e52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb048dce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "\n",
    "lr = 0.0001\n",
    "decay_rate = lr / epoch\n",
    "momentum = 0.99\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=lr, weight_decay=decay_rate, epsilon=1e-07, amsgrad=False)\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=lr, momentum=momentum, weight_decay=decay_rate, nesterov=False)\n",
    "checkpoint = ModelCheckpoint(output_weights_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "# class_weigths = dict(zip(range(len(neg_weights)), neg_weights))\n",
    "# weighted_loss = get_weighted_loss(pos_weights, neg_weights)\n",
    "bce_ls = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0)\n",
    "\n",
    "metric_auc = tf.keras.metrics.AUC(multi_label=True)\n",
    "\n",
    "model.compile(loss=bce_ls, optimizer=sgd, metrics=[metric_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f9abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time() \n",
    "history = model.fit(image_train, epochs=epoch, validation_data=image_val, callbacks=[checkpoint,PlotLossesKeras()],verbose=1)\n",
    "end_train = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05d793-fbf4-485b-94cc-543b4c149996",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=========== TRAINING ENDED IN {} min ================\".format(end_train/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46c5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(output_dir, 'model_{}'.format(model_name))\n",
    "model.save(save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed547c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_weight_model_path = os.path.join(output_dir, '{}_weights.h5'.format(model_name))\n",
    "model.save_weights(final_weight_model_path)\n",
    "file_stats = os.stat(final_weight_model_path)\n",
    "model_size = round(file_stats.st_size / (1024 * 1024), 2)\n",
    "model_parameter = model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262f6d7-7f3a-4cce-b278-d225682618b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ce26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dadb25-39ee-4513-a171-ddb8f964129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca88f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load Model\n",
    "from tensorflow import keras\n",
    "# model_fusion = keras.models.load_model(save_model_path, custom_objects={\n",
    "#     \"binary_crossentropy_weighted_loss\": util.set_binary_crossentropy_weighted_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde6c093-5d65-43c7-9c7e-e42d1ddf44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fusion = keras.models.load_model(save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448bb8d8-567f-4250-8a1c-4e3ff989d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_vals = model_fusion.predict_generator(image_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86268429-51e9-48e4-87fd-0a164283a3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auc_rocs = util.get_roc_curve(labels, predicted_vals, image_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2e4258-f31c-439d-806b-f18d2b7206d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_auroc = np.mean(auc_rocs)\n",
    "print(\"Mean AUC: {}\".format(mean_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde830f6-9ced-4b64-a23d-1d5e288db144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47477536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import multilabel_confusion_matrix\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# start = time.time()\n",
    "# y_prob = model_fusion.predict(image_val)\n",
    "# end_test = time.time() - start\n",
    "\n",
    "# y_pred = np.argmax(y_prob, axis=1)\n",
    "# y_true = image_val.classes\n",
    "\n",
    "# print(\"Precision:\", precision_score(y_true, y_pred, average='weighted'), \"Recall:\", recall_score(y_true, y_pred, average='weighted'))\n",
    "\n",
    "# cm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# a = []\n",
    "\n",
    "# for i in range(len(cm)):\n",
    "#     a.append(cm[i].ravel())\n",
    "\n",
    "# tp, fn, fp, tn =np.sum(np.array(a), axis = 0)\n",
    "\n",
    "# print(\"tp, fn, fp, tn:\", tp, fn, fp, tn)\n",
    "\n",
    "# print(\"Specificity:\", tn / (tn+fp), \"Sensitivity:\", tp / (tp+fn))\n",
    "# print(\"F1-Score:\", f1_score(y_true, y_pred, average='weighted'), \"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "\n",
    "# Specificty = tn / (tn+fp)\n",
    "# Sensitivity = tp / (tp+fn)\n",
    "# F1_Score = f1_score(y_true, y_pred, average='weighted')\n",
    "# Accuracy = accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = [y_true, y_pred]\n",
    "# pd.DataFrame(result).to_csv(\"{}_{}_result.csv\".format(model_name, n_fold))\n",
    "# pd.DataFrame(y_prob).to_csv(\"{}_{}_probability.csv\".format(model_name, n_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eece65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_true, y_pred)\n",
    "# m_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "# print(fpr_keras, tpr_keras, thresholds_keras, m_auc)\n",
    "\n",
    "# from sklearn.metrics import auc\n",
    "# auc_keras = auc(fpr_keras, tpr_keras)\n",
    "# print(auc_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keep probabilities for the positive outcome only\n",
    "# lr_probs = y_prob[:, 1]\n",
    "# lr_auc = roc_auc_score(y_true, lr_probs)\n",
    "# print('Model Fusion: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# lr_fpr, lr_tpr, _ = roc_curve(y_true, lr_probs)\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# font={'size':'15'}\n",
    "# plt.rc('font',**font)\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "# plt.plot(lr_fpr, lr_tpr, marker='.', label='{} Model ROC curve (area = %0.2f)'.format(model_name) % lr_auc)\n",
    "\n",
    "# roc_auc = [lr_fpr, lr_fpr]\n",
    "# pd.DataFrame(roc_auc).to_csv(\"{}_roc_auc.csv\".format(model_name))\n",
    "\n",
    "# # axis labels\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# # show the legend\n",
    "# plt.legend()\n",
    "\n",
    "# AUC_Score = lr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a6ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result = [Specificty, Sensitivity, F1_Score, Accuracy, AUC_Score, end_train, end_test, model_size, model_parameter]\n",
    "# colname = ['Specificty', 'Sensitivity', 'F1_Score', 'Accuracy', 'AUC_Score', 'end_train', 'end_test', 'model_size', 'model_parameter']\n",
    "\n",
    "# pd.DataFrame([Result], columns=colname).to_csv(\"{}_fold_\".format(model_name)+str(n_fold)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(15, 15))\n",
    "\n",
    "# labels = [\"Sperm\", \"Impurity\"]\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "# plt.rcParams['figure.figsize']=[15,15]\n",
    "# font={'size':'30'}\n",
    "# plt.rc('font',**font)\n",
    "# disp.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27757846-d52f-411a-ad6c-c8cfb460fa2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jeremie_env",
   "language": "python",
   "name": "jeremie_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
