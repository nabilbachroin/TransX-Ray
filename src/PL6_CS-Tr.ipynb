{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2109f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_fold= 1\n",
    "total_fold= '5'\n",
    "use_enchanced_dataset= False\n",
    "model_name= \"CS-Tr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477ca1e-19f8-49f1-aaac-01cf171a7949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os, pickle, time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import *\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential, model_from_json, load_model\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from callback import MultipleClassAUROC\n",
    "\n",
    "import util\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from livelossplot import PlotLossesKeras\n",
    "from keras.initializers import RandomNormal\n",
    "from swintransformer import SwinTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936dfef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "print(\"Test built: {}\".format(tf.test.is_built_with_cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53372361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if use_enchanced_dataset == True:\n",
    "    IMAGE_DIR = \"/home/cries/Dataset/X-Ray/enchanced/\"\n",
    "else:\n",
    "    IMAGE_DIR = \"/home/cries/Dataset/X-Ray/original/images/\"\n",
    "    \n",
    "train_df= pd.read_csv(\"/home/cries/Dataset/X-Ray/DataFrame/\" + str(total_fold) + \"Fold/\" + \"train_Fold\" + str(n_fold) + \".csv\").loc[:,'Image Index':]\n",
    "test_df= pd.read_csv(\"/home/cries/Dataset/X-Ray/DataFrame/\" + str(total_fold) + \"Fold/\" + \"test_Fold\" + str(n_fold) + \".csv\").loc[:,'Image Index':]\n",
    "\n",
    "labels = ['No Findings',            'Cardiomegaly', \n",
    "          'Emphysema',              'Effusion', \n",
    "          'Hernia',                 'Infiltration', \n",
    "          'Mass',                   'Nodule', \n",
    "          'Atelectasis',            'Pneumothorax',\n",
    "          'Pleural_Thickening',     'Pneumonia', \n",
    "          'Fibrosis',               'Edema', \n",
    "          'Consolidation']\n",
    "labels_col= labels\n",
    "index_col= \"Image Index\"\n",
    "print(\"Leakage between train and test: {}\".format(util.check_for_leakage(train_df, test_df, 'Image Index')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3cebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting\n",
    "seed= 1\n",
    "batch_size= 32\n",
    "target_w= 320; target_h= 320; dim= (3,)\n",
    "# target_w= 224; target_h= 224; dim= (3,)\n",
    "image_size_target= (target_w,target_h)\n",
    "image_shape= image_size_target + dim\n",
    "class_mode= 'raw'   # raw, categorical \n",
    "\n",
    "use_aug= True\n",
    "use_normalize= True\n",
    "aug_norm = (use_aug, use_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b0e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_generator(use_Aug, use_Normalize):\n",
    "    # == Aug and Normalize Image \n",
    "    if use_Aug== True and use_Normalize== True:\n",
    "        return ImageDataGenerator(\n",
    "            brightness_range=[0.33,0.33],\n",
    "            zoom_range=0.33,\n",
    "            rescale= 1./255,        \n",
    "            horizontal_flip= True,\n",
    "            samplewise_center= True,\n",
    "            samplewise_std_normalization= True\n",
    "            )\n",
    "    # == Aug Image\n",
    "    if use_Aug== True and use_Normalize== False:\n",
    "        return ImageDataGenerator(\n",
    "            rescale= 1./255,        \n",
    "            horizontal_flip= True,\n",
    "            height_shift_range= 0.5,\n",
    "            width_shift_range= 0.5,\n",
    "            vertical_flip= True,\n",
    "            rotation_range= 20,\n",
    "            fill_mode= \"nearest\"\n",
    "            )\n",
    "    # == Normalize Image\n",
    "    if use_Aug== False and use_Normalize== True:\n",
    "        return ImageDataGenerator(\n",
    "            rescale= 1./255,\n",
    "            horizontal_flip= True,\n",
    "            samplewise_center= True,\n",
    "            samplewise_std_normalization= True\n",
    "            )\n",
    "    # == Without\n",
    "    if use_Aug== False and use_Normalize== False:\n",
    "        return ImageDataGenerator()\n",
    "\n",
    "# ======================= IMAGE GENERATOR ===================\n",
    "\n",
    "# === Image Train Generator\n",
    "print(\"============ getting train generator ===========\") \n",
    "image_train= prepare_generator(*aug_norm).flow_from_dataframe(\n",
    "    dataframe= train_df,\n",
    "    directory= IMAGE_DIR,\n",
    "    x_col= index_col,\n",
    "    y_col= labels,\n",
    "    class_mode= class_mode,\n",
    "    batch_size= batch_size,\n",
    "    shuffle= True,\n",
    "    target_size= image_size_target\n",
    ")\n",
    "\n",
    "# === Image Validation and Test Generator\n",
    "print(\"\")\n",
    "print(\"==== getting train and test/valid generators ====\")\n",
    "raw_train_generator= prepare_generator(False, False).flow_from_dataframe(\n",
    "                        dataframe= train_df,\n",
    "                        directory= IMAGE_DIR,\n",
    "                        x_col= index_col,\n",
    "                        y_col= labels,\n",
    "                        class_mode= class_mode,\n",
    "                        batch_size= batch_size,\n",
    "                        shuffle= True,\n",
    "                        target_size= image_size_target\n",
    "                    )\n",
    "batch= raw_train_generator.next()\n",
    "data_sample= batch[0]\n",
    "imagegenerator= prepare_generator(*aug_norm)\n",
    "imagegenerator.fit(data_sample)\n",
    "image_val = imagegenerator.flow_from_dataframe(\n",
    "                        dataframe= test_df,\n",
    "                        directory= IMAGE_DIR,\n",
    "                        x_col= index_col,\n",
    "                        y_col= labels,\n",
    "                        class_mode= class_mode,\n",
    "                        batch_size= batch_size,\n",
    "                        shuffle= False,\n",
    "                        target_size= image_size_target\n",
    "                    )\n",
    "\n",
    "x, y = image_train.__getitem__(0)\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(x[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8da0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=labels, height=np.mean(image_train.labels, axis=0))\n",
    "plt.title(\"Frequency of Each Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c6c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_class_freqs(labels):\n",
    "    # total number of patients (rows)\n",
    "    N = labels.shape[0]\n",
    "    positive_frequencies = np.sum(labels, axis = 0) / N\n",
    "    negative_frequencies = 1 - positive_frequencies\n",
    "    return positive_frequencies, negative_frequencies\n",
    "\n",
    "freq_pos, freq_neg = compute_class_freqs(image_train.labels)\n",
    "freq_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad2b61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.xticks(rotation=90)\n",
    "f = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7428e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_weights = freq_neg\n",
    "neg_weights = freq_pos\n",
    "pos_contribution = freq_pos * pos_weights \n",
    "neg_contribution = freq_neg * neg_weights\n",
    "\n",
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": pos_contribution})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} \n",
    "                        for l,v in enumerate(neg_contribution)], ignore_index=True)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = util.generate_class_weights(image_train.labels, multi_class=False, one_hot_encoded=True)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674bb3e-aa68-42f9-bd52-807f16325506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs= Input(shape=image_shape)\n",
    "# inputs= Input(shape=(224,224,3))\n",
    "\n",
    "num_class = len(labels)\n",
    "print(\"~> image shape={}\\n~> num_class={}\".format(image_shape,num_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d18f6f3-0777-4f44-a681-21ff17838c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "image_size = 15  # We'll resize input images to this size\n",
    "patch_size = 5  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74627204-6d5f-4725-baa4-120aab199e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        # layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        # layers.RandomFlip(\"horizontal\"),\n",
    "        # layers.RandomRotation(factor=0.02),\n",
    "        # layers.RandomZoom(\n",
    "        #     height_factor=0.2, width_factor=0.2\n",
    "        # ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "# data_augmentation.layers[0].adapt(image_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41bc73-8273-4e0f-bc3f-fcf55699adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72048f0-a76c-4ead-9ea5-a5047e1a8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0504c78-d243-47e1-af8e-c2e976f16389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee5a876-411f-4340-a9be-948bd204b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier(layer):\n",
    "    inputs = layer\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    prediction = layers.Dense(num_class, activation=\"sigmoid\")(features)\n",
    "    # Create the Keras model.\n",
    "    # model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375be90d-bbdb-4261-83f2-e40c39c34ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_class = len(labels)\n",
    "tf_weights_path = '/home/cries/Workshop/X-Ray/TransX-Ray/jeremie/chexnet_pretrained/brucechou1983_CheXNet_Keras_0.3.0_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da78c3e-36d5-4f93-95e9-e2ff095831e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mdl = tf.keras.applications.DenseNet121(weights=tf_weights_path, include_top=True, classes=14, input_tensor=inputs)\n",
    "\n",
    "pretrained = Model(inputs=inputs, outputs=mdl.layers[-3].output)\n",
    "pretrained.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03c3d7-f7e3-4815-b976-9c887898e659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(input_layer):\n",
    "\n",
    "    mdl = pretrained(input_layer)\n",
    "    mdl = LayerNormalization()(mdl)\n",
    "    \n",
    "    \n",
    "    vit = create_vit_classifier(mdl)\n",
    "    # prediction = Dense(num_class, activation=\"sigmoid\")(vit)\n",
    "    \n",
    "    return vit\n",
    "\n",
    "input_layer = inputs\n",
    "output = build_model(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec164f73-08b6-47ba-be27-4bb6dc6b1eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(input_layer, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bcb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './output_weights/{}'.format(model_name)\n",
    "weight_path = '{}_ckp_weights.h5'.format(model_name)\n",
    "\n",
    "output_weights_path = os.path.join(output_dir, weight_path)\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb048dce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "\n",
    "epoch = 100\n",
    "\n",
    "lr = 0.001\n",
    "decay_rate = lr / epoch\n",
    "momentum = 0.99\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=decay_rate, beta_2=decay_rate*decay_rate, epsilon=1e-07, amsgrad=False)\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=lr, momentum=momentum, weight_decay=decay_rate, nesterov=False)\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=lr, momentum=momentum, nesterov=False)\n",
    "checkpoint = ModelCheckpoint(output_weights_path, monitor='loss', verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "bfce_ls = tf.losses.BinaryCrossentropy(label_smoothing = 0.0)\n",
    "metric_auc = tf.keras.metrics.AUC(multi_label=True)\n",
    "model.compile(loss=bfce_ls, optimizer=sgd, metrics=[metric_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc = MultipleClassAUROC(\n",
    "            sequence=image_val,\n",
    "            class_names=labels,\n",
    "            weights_path=output_weights_path,\n",
    "            workers=1,\n",
    "        )\n",
    "adaptive_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, mode=\"min\", min_lr=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f42190",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() \n",
    "history = model.fit(image_train, epochs=epoch, validation_data=image_val, callbacks=[checkpoint,PlotLossesKeras(), auroc, adaptive_lr],verbose=1)\n",
    "end_train = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f9abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# history = model.fit(image_train, epochs=epoch, validation_data=image_val, callbacks=[checkpoint,PlotLossesKeras()],verbose=1)\n",
    "# end_train = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46c5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(output_dir, 'model_{}'.format(model_name))\n",
    "model.save(save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed547c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_weight_model_path = os.path.join(output_dir, '{}_weights.h5'.format(model_name))\n",
    "model.save_weights(final_weight_model_path)\n",
    "file_stats = os.stat(final_weight_model_path)\n",
    "model_size = round(file_stats.st_size / (1024 * 1024), 2)\n",
    "model_parameter = model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ce26a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca88f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_fusion = keras.models.load_model(save_model_path)\n",
    "predicted_vals = model_fusion.predict_generator(image_val, steps = len(image_val))\n",
    "auc_rocs = util.get_roc_curve(labels, predicted_vals, image_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff0a74c-d7f9-4fc7-bd0a-44a5ad2d3197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_auroc = np.mean(auc_rocs)\n",
    "print(\"Mean AUC: {}\".format(mean_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde830f6-9ced-4b64-a23d-1d5e288db144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "print(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nabil_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (default, Nov 15 2020, 14:28:56) \n[GCC 7.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2be0ae400c5b237d6011169f6eb0a199b380535513ae233c0852e6d69a4e9a6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
